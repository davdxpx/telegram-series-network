import httpx
from fastapi import APIRouter, Request, HTTPException, Response, status, Depends
from fastapi.responses import StreamingResponse, JSONResponse, FileResponse
from app.models import Episode, Series, Bundle, User, StorageChannel
from app.config import settings
from app.webapp.auth import verify_admin
from beanie import PydanticObjectId
from typing import List, Dict, Optional
import logging
import os
from pydantic import BaseModel
import re

# Import Handlers for Batch Logic
from app.handlers import batch_import

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/webapp", tags=["webapp"])

# --- WebApp Entry Points ---

@router.get("/user", response_class=FileResponse)
async def serve_user_app():
    return FileResponse("app/webapp/static/user.html")

@router.get("/admin", response_class=FileResponse)
async def serve_admin_app():
    return FileResponse("app/webapp/static/admin.html")

# --- API Endpoints for Frontend ---

@router.get("/bundles", response_model=List[Bundle])
async def get_bundles():
    return await Bundle.find_all().to_list()

@router.post("/bundles", dependencies=[Depends(verify_admin)])
async def create_bundle(bundle: Bundle):
    # ID is auto-generated by MongoDB
    await bundle.create()
    return bundle

@router.get("/series/{bundle_id}", response_model=List[Series])
async def get_series_in_bundle(bundle_id: str):
    return await Series.find(Series.bundle_id == PydanticObjectId(bundle_id)).to_list()

@router.get("/episodes/{series_id}", response_model=List[Episode])
async def get_episodes(series_id: str):
    return await Episode.find(Episode.series_id == PydanticObjectId(series_id)).sort(+Episode.season_id, +Episode.episode_number).to_list()

# --- Storage Channels API ---

class StorageChannelCreate(BaseModel):
    channel_id: int
    name: str
    invite_link: Optional[str] = None

@router.get("/channels", response_model=List[StorageChannel], dependencies=[Depends(verify_admin)])
async def get_storage_channels():
    return await StorageChannel.find_all().to_list()

@router.post("/channels", dependencies=[Depends(verify_admin)])
async def create_storage_channel(channel: StorageChannelCreate):
    existing = await StorageChannel.find_one(StorageChannel.channel_id == channel.channel_id)
    if existing:
        raise HTTPException(status_code=400, detail="Channel already registered")

    new_channel = StorageChannel(**channel.model_dump())
    await new_channel.create()
    return new_channel

@router.delete("/channels/{channel_id}", dependencies=[Depends(verify_admin)])
async def delete_storage_channel(channel_id: int):
    channel = await StorageChannel.find_one(StorageChannel.channel_id == channel_id)
    if not channel:
        raise HTTPException(status_code=404, detail="Channel not found")
    await channel.delete()
    return {"status": "deleted"}

# --- Search API ---

@router.get("/search")
async def search_content(q: str):
    if not q or len(q) < 2:
        return []

    # Simple regex search on Series name
    # Beanie supports regex queries
    series = await Series.find({"name": {"$regex": q, "$options": "i"}}).to_list()
    return series

# --- Batch Import API ---

class BatchStartRequest(BaseModel):
    channel_id: int
    bundle_id: str

class BatchStopRequest(BaseModel):
    channel_id: int

@router.post("/batch/start", dependencies=[Depends(verify_admin)])
async def start_batch_endpoint(data: BatchStartRequest):
    """
    Triggers the batch import process for a given channel and bundle.
    """
    # Verify bundle exists
    bundle = await Bundle.get(PydanticObjectId(data.bundle_id))
    if not bundle:
        raise HTTPException(status_code=404, detail="Bundle not found")

    await batch_import.start_batch(data.channel_id, data.bundle_id)
    return {"status": "started", "channel_id": data.channel_id, "bundle_id": data.bundle_id}

@router.post("/batch/stop", dependencies=[Depends(verify_admin)])
async def stop_batch_endpoint(data: BatchStopRequest):
    await batch_import.stop_batch(data.channel_id)
    return {"status": "stopped", "channel_id": data.channel_id}

# --- Continue Watching / Progress API ---

class ProgressUpdate(BaseModel):
    user_id: int
    episode_id: str
    progress: float # 0.0 to 1.0 or timestamp

@router.post("/progress")
async def update_progress(data: ProgressUpdate):
    user = await User.find_one(User.telegram_id == data.user_id)
    if not user:
        raise HTTPException(status_code=404, detail="User not found")

    # Update progress map
    if user.watch_progress is None:
        user.watch_progress = {}

    user.watch_progress[data.episode_id] = data.progress
    await user.save()
    return {"status": "updated"}

@router.get("/continue-watching/{user_id}")
async def get_continue_watching(user_id: int):
    user = await User.find_one(User.telegram_id == user_id)
    if not user or not user.watch_progress:
        return []

    # Get last 5 watched episodes
    # Sort by value? No, Beanie dict doesn't store timestamps of update easily.
    # Just return all for now or filter.

    episode_ids = list(user.watch_progress.keys())
    episodes = await Episode.find(Episode.id.in_([PydanticObjectId(eid) for eid in episode_ids])).to_list()

    # Sort or format?
    # Return enriched episodes with progress
    results = []
    for ep in episodes:
        results.append({
            "episode": ep,
            "progress": user.watch_progress.get(str(ep.id), 0)
        })
    return results

# --- Streaming Proxy ---

@router.get("/stream/{file_id}")
async def stream_video(file_id: str, request: Request):
    """
    Proxies the video stream from Telegram servers to the client.
    Handles Range requests to allow seeking.
    """

    # 1. Get File Path from Telegram API
    # We need to call getFile to get the download path
    # This path is valid for 1 hour. We can cache this.

    # Using direct request to bot API for speed (skipping aiogram wrapper for raw http)
    async with httpx.AsyncClient() as client:
        file_info_resp = await client.get(f"https://api.telegram.org/bot{settings.BOT_TOKEN}/getFile?file_id={file_id}")
        if file_info_resp.status_code != 200:
            raise HTTPException(status_code=404, detail="File not found on Telegram")

        file_path = file_info_resp.json()["result"]["file_path"]
        download_url = f"https://api.telegram.org/file/bot{settings.BOT_TOKEN}/{file_path}"

        # 2. Handle Range Header
        range_header = request.headers.get("range")
        headers = {}
        if range_header:
            headers["Range"] = range_header

        # 3. Stream from Telegram
        # We need a client that supports streaming

        # This is a simplified proxy. For production high-load,
        # consider using Nginx or a dedicated streaming server that handles Range requests better.
        # Python's httpx/aiohttp can do it but it consumes python resources.

        async def iterate_stream():
             async with httpx.AsyncClient() as stream_client:
                async with stream_client.stream("GET", download_url, headers=headers) as response:
                    # Forward headers
                    # Content-Range is crucial for seeking
                    if "Content-Range" in response.headers:
                        pass # We will set it in the response below

                    async for chunk in response.aiter_bytes():
                        yield chunk

        # We need to fetch the headers from Telegram first to set correct response headers
        # Use a HEAD request or a GET with stream=True but don't read body yet

        # Simpler approach: Redirect?
        # No, requirements said "never expose bot token".
        # Redirect exposes the URL which contains the token in the path!
        # So we MUST proxy.

        try:
             async with httpx.AsyncClient() as head_client:
                # We start a stream just to get headers
                async with head_client.stream("GET", download_url, headers=headers) as upstream_response:

                    response_headers = {
                        "Content-Type": upstream_response.headers.get("Content-Type", "video/mp4"),
                        "Accept-Ranges": "bytes",
                        "Content-Length": upstream_response.headers.get("Content-Length"),
                        "Content-Range": upstream_response.headers.get("Content-Range"),
                    }

                    # Remove None values
                    response_headers = {k: v for k, v in response_headers.items() if v is not None}

                    return StreamingResponse(
                        iterate_stream(),
                        status_code=upstream_response.status_code,
                        headers=response_headers,
                        media_type="video/mp4" # Force video
                    )
        except Exception as e:
            logger.error(f"Streaming error: {e}")
            raise HTTPException(status_code=500, detail="Streaming failed")
